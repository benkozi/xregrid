from pathlib import Path
from typing import Union, Optional

import numpy as np
import xarray as xr
from scipy.sparse import coo_matrix


class SMM:
    """
    Sparse Matrix Multiplication (SMM) for regridding.

    This class provides a lightweight interface for applying ESMF-generated
    regridding weights to xarray DataArrays, supporting both NumPy and Dask
    backends.
    """

    def __init__(self, weights: Union[Path, str, xr.Dataset]) -> None:
        """
        Initialize the SMM object with a weights file and store the derived COO matrix.

        Parameters
        ----------
        weights : Path, str, or xr.Dataset
            Path to the netCDF ESMF weight file or an xarray Dataset containing the weights.
        """
        # Use xarray Dataset or Path
        if isinstance(weights, (str, Path)):
            ds_weights = xr.open_dataset(weights)
        else:
            ds_weights = weights

        # ESMF weight files have dimensions n_s, n_a, n_b
        # n_s: number of non-zero elements
        # n_a: size of source grid (flattened)
        # n_b: size of target grid (flattened)
        self.n_s = ds_weights.sizes["n_s"]

        # If generated by Regridder, these attributes exist
        if "n_src" in ds_weights.attrs:
            self.n_a = ds_weights.attrs["n_src"]
            self.n_b = ds_weights.attrs["n_dst"]
        else:
            # Fallback for standard ESMF weight files
            # Sometimes n_a/n_b are not dimensions but variables or just implied by row/col max
            self.n_a = int(ds_weights["col"].max())
            self.n_b = int(ds_weights["row"].max())

        # ESMF weights are 1-indexed
        row = ds_weights["row"].values - 1
        col = ds_weights["col"].values - 1
        data = ds_weights["S"].values

        self._matrix = coo_matrix((data, (row, col)), shape=(self.n_b, self.n_a))

        # Store attributes for provenance and reconstruction
        self.attrs = ds_weights.attrs

    def __call__(
        self,
        src: xr.DataArray,
        time_dim: Optional[str] = None,
        level_dim: Optional[str] = None,
    ) -> xr.DataArray:
        """
        Apply the SMM to the source data array creating a regridding destination array.

        Parameters
        ----------
        src : xr.DataArray
            The source data array to be regridded.
        time_dim : str, optional
            The name of the time dimension, if present.
        level_dim : str, optional
            The name of the level dimension, if present.

        Returns
        -------
        xr.DataArray
            The regridded destination data array.
        """
        # Identify spatial dimensions (those that are not time or level)
        spatial_dims = [d for d in src.dims if d not in (time_dim, level_dim)]

        def _apply_smm(data, matrix):
            # data is (..., spatial)
            original_shape = data.shape
            # The spatial size is the product of all remaining dimensions
            # apply_ufunc will have moved core dims to the end.
            # If multiple core dims are provided, they are flattened in the UFUNC input.
            # Actually, if we provide multiple input_core_dims, the ufunc receives them as-is.
            # However, ESMF weights are for a flattened spatial dimension.

            # Since we use input_core_dims=spatial_dims, data will have shape (..., *spatial_dims_shape)
            # We need to flatten the spatial dimensions to match the matrix.
            n_spatial_dims = len(spatial_dims)
            spatial_shape = original_shape[len(original_shape) - n_spatial_dims :]
            other_shape = original_shape[: len(original_shape) - n_spatial_dims]

            spatial_size = int(np.prod(spatial_shape))
            if spatial_size != matrix.shape[1]:
                raise ValueError(
                    f"Source spatial size {spatial_size} does not match "
                    f"weights source size {matrix.shape[1]}"
                )

            # Flatten leading dimensions and spatial dimensions
            n_other = int(np.prod(other_shape))
            flat_data = data.reshape(n_other, spatial_size)

            # Apply weights: (n_b, n_a) @ (n_a, n_other) -> (n_b, n_other)
            # But matrix @ flat_data.T is (n_b, n_other)
            res = (matrix @ flat_data.T).T

            # Reshape back: (..., n_b)
            new_shape = other_shape + (matrix.shape[0],)
            return res.reshape(new_shape)

        # Use apply_ufunc for backend-agnostic behavior
        dst = xr.apply_ufunc(
            _apply_smm,
            src,
            kwargs={"matrix": self._matrix},
            input_core_dims=[spatial_dims],
            output_core_dims=[["target_spatial"]],
            dask="parallelized",
            output_dtypes=[src.dtype],
            dask_gufunc_kwargs={
                "allow_rechunk": True,
                "output_sizes": {"target_spatial": self.n_b},
            },
        )

        # Update provenance
        if "history" in dst.attrs:
            dst.attrs["history"] += "\nRegridded using xregrid.SMM"
        else:
            dst.attrs["history"] = "Regridded using xregrid.SMM"

        return dst