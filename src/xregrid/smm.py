from pathlib import Path
from typing import Union, Optional

import numpy as np
import xarray as xr
from scipy.sparse import coo_matrix


class SMM:
    """
    Sparse Matrix Multiplication (SMM) for regridding.

    This class provides a lightweight interface for applying ESMF-generated
    regridding weights to xarray DataArrays, supporting both NumPy and Dask
    backends.
    """

    def __init__(self, weights: Union[Path, str, xr.Dataset]) -> None:
        """
        Initialize the SMM object with a weights file and store the derived COO matrix.

        Parameters
        ----------
        weights : Path, str, or xr.Dataset
            Path to the netCDF ESMF weight file or an xarray Dataset containing the weights.
        """
        # Use xarray Dataset or Path
        if isinstance(weights, (str, Path)):
            ds_weights = xr.open_dataset(weights)
        else:
            ds_weights = weights

        # ESMF weight files have dimensions n_s, n_a, n_b
        # n_s: number of non-zero elements
        # n_a: size of source grid (flattened)
        # n_b: size of target grid (flattened)
        self.n_s = ds_weights.sizes["n_s"]

        # If generated by Regridder, these attributes exist
        if "n_src" in ds_weights.attrs:
            self.n_a = ds_weights.attrs["n_src"]
            self.n_b = ds_weights.attrs["n_dst"]
        else:
            # Fallback for standard ESMF weight files
            # Sometimes n_a/n_b are not dimensions but variables or just implied by row/col max
            self.n_a = int(ds_weights["col"].max())
            self.n_b = int(ds_weights["row"].max())

        # ESMF weights are 1-indexed
        row = ds_weights["row"].values - 1
        col = ds_weights["col"].values - 1
        data = ds_weights["S"].values

        self._matrix = coo_matrix((data, (row, col)), shape=(self.n_b, self.n_a))

        # Store attributes for provenance and reconstruction
        self.attrs = ds_weights.attrs

        # Store target shape and dimensions if available for reshaping
        self.shape_dst = None
        self.dims_dst = None
        if "shape_dst" in ds_weights.attrs:
            import ast

            try:
                self.shape_dst = tuple(ast.literal_eval(ds_weights.attrs["shape_dst"]))
                self.dims_dst = tuple(ast.literal_eval(ds_weights.attrs["dims_target"]))
            except (ValueError, SyntaxError):
                # Fallback if it's already a list/tuple or other format
                self.shape_dst = tuple(ds_weights.attrs["shape_dst"])
                self.dims_dst = tuple(ds_weights.attrs["dims_target"])

    def __call__(
        self,
        src: xr.DataArray,
        time_dim: Optional[str] = None,
        level_dim: Optional[str] = None,
    ) -> xr.DataArray:
        """
        Apply the SMM to the source data array creating a regridding destination array.

        Parameters
        ----------
        src : xr.DataArray
            The source data array to be regridded.
        time_dim : str, optional
            The name of the time dimension, if present.
        level_dim : str, optional
            The name of the level dimension, if present.

        Returns
        -------
        xr.DataArray
            The regridded destination data array.
        """
        # Identify spatial dimensions (those that are not time or level)
        spatial_dims = [d for d in src.dims if d not in (time_dim, level_dim)]

        def _apply_smm(data, matrix):
            # data is (..., spatial)
            original_shape = data.shape
            # The spatial size is the product of all remaining dimensions
            # apply_ufunc will have moved core dims to the end.
            # If multiple core dims are provided, they are flattened in the UFUNC input.
            # Actually, if we provide multiple input_core_dims, the ufunc receives them as-is.
            # However, ESMF weights are for a flattened spatial dimension.

            # Since we use input_core_dims=spatial_dims, data will have shape (..., *spatial_dims_shape)
            # We need to flatten the spatial dimensions to match the matrix.
            n_spatial_dims = len(spatial_dims)
            spatial_shape = original_shape[len(original_shape) - n_spatial_dims :]
            other_shape = original_shape[: len(original_shape) - n_spatial_dims]

            spatial_size = int(np.prod(spatial_shape))
            if spatial_size != matrix.shape[1]:
                raise ValueError(
                    f"Source spatial size {spatial_size} does not match "
                    f"weights source size {matrix.shape[1]}"
                )

            # Flatten leading dimensions and spatial dimensions
            n_other = int(np.prod(other_shape))
            flat_data = data.reshape(n_other, spatial_size)

            # Apply weights: (n_b, n_a) @ (n_a, n_other) -> (n_b, n_other)
            # But matrix @ flat_data.T is (n_b, n_other)
            res = (matrix @ flat_data.T).T

            # Reshape back: (..., n_b)
            new_shape = other_shape + (matrix.shape[0],)
            return res.reshape(new_shape)

        # Use apply_ufunc for backend-agnostic behavior
        dst = xr.apply_ufunc(
            _apply_smm,
            src,
            kwargs={"matrix": self._matrix},
            input_core_dims=[spatial_dims],
            output_core_dims=[["target_spatial"]],
            dask="parallelized",
            output_dtypes=[src.dtype],
            dask_gufunc_kwargs={
                "allow_rechunk": True,
                "output_sizes": {"target_spatial": self.n_b},
            },
        )

        # Reshape and rename back to target spatial dimensions if metadata is available
        if self.dims_dst and self.shape_dst:
            # Current dims: (..., "target_spatial")
            # We want to replace "target_spatial" with self.dims_dst
            # And reshape the data accordingly
            non_spatial_dims = [d for d in dst.dims if d != "target_spatial"]
            new_dims = tuple(non_spatial_dims) + self.dims_dst

            def _reshape_output(data, target_shape):
                # data has shape (..., n_b)
                # target_shape is e.g. (9, 18)
                other_shape = data.shape[:-1]
                return data.reshape(other_shape + target_shape)

            # Re-apply apply_ufunc or just use xarray operations?
            # xarray.DataArray.stack/unstack/reshape is tricky with dask and core dims.
            # A simpler way is to use dst.stack(target_spatial=self.dims_dst) but in reverse.
            # Actually, we can just use .assign_coords and .reshape if it's eager,
            # but for lazy we should be careful.

            # Easiest way to restore dimensions in xarray:
            dst = dst.assign_coords(target_spatial=np.arange(self.n_b))
            
            # If we want to be truly Aero-compliant and lazy-friendly:
            # we can use another apply_ufunc to reshape or just use xr.DataArray methods.
            # Since n_b is flat, we can unstack it if we had coordinates.
            # But we don't have the multi-index.
            
            # Let's use a simple reshape and rename
            dst_data = dst.data.reshape(dst.shape[:-1] + self.shape_dst)
            dst = xr.DataArray(
                dst_data,
                dims=new_dims,
                coords={d: src.coords[d] for d in non_spatial_dims if d in src.coords},
                attrs=dst.attrs,
                name=dst.name,
            )

            # Re-attach target spatial coordinates if they were not in src
            # (which is typical for regridding)
            # We can't easily get them from ESMF weights file unless they were stored as variables.
            # Standard ESMF weights don't store them. 
            # Our Regridder could store them, but currently it only stores shapes/dims.

        # Update provenance
        if "history" in dst.attrs:
            dst.attrs["history"] += "\nRegridded using xregrid.SMM"
        else:
            dst.attrs["history"] = "Regridded using xregrid.SMM"

        return dst